{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3) (50000, 1)\n",
      "Testing data shape: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding if needed\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def exclue_class(x_data,y_data, excluded_cindex):\n",
    "    x_filtered,y_filtered = [],[]\n",
    "    for cur_x, cur_y in zip(x_data,y_data):\n",
    "        if np.argmax(cur_y) in excluded_cindex:\n",
    "            continue\n",
    "        x_filtered.append(cur_x)\n",
    "        y_filtered.append(cur_y)\n",
    "    return np.array(x_filtered),np.array(y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cindex(cur_y):\n",
    "    temp = set()\n",
    "    for x in cur_y:\n",
    "        temp.add(np.argmax(x))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_1 :  {0, 2, 4, 5, 6, 8, 9}\n",
      "y_train_2 :  {0, 1, 3, 4, 6, 7, 9}\n",
      "y_train_3 :  {0, 1, 2, 3, 5, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "x_train_1, y_train_1  = exclue_class(x_train, y_train_one_hot, excluded_cindex=[1, 3, 7])\n",
    "print(\"y_train_1 : \",check_cindex(y_train_1))\n",
    "\n",
    "\n",
    "x_train_2, y_train_2 = exclue_class(x_train, y_train_one_hot, excluded_cindex=[2, 5, 8])\n",
    "print(\"y_train_2 : \",check_cindex(y_train_2))\n",
    "\n",
    "x_train_3, y_train_3 = exclue_class(x_train, y_train_one_hot, excluded_cindex=[4, 6, 9])\n",
    "print(\"y_train_3 : \",check_cindex(y_train_3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_1 :  {0, 2, 4, 5, 6, 8, 9}\n",
      "y_test_2 :  {0, 1, 3, 4, 6, 7, 9}\n",
      "y_test_3 :  {0, 1, 2, 3, 5, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "x_test_1, y_test_1  = exclue_class(x_test, y_test_one_hot, excluded_cindex=[1, 3, 7])\n",
    "print(\"y_test_1 : \",check_cindex(y_test_1))\n",
    "\n",
    "x_test_2, y_test_2  = exclue_class(x_test, y_test_one_hot, excluded_cindex=[2, 5, 8])\n",
    "print(\"y_test_2 : \",check_cindex(y_test_2))\n",
    "\n",
    "x_test_3, y_test_3  = exclue_class(x_test, y_test_one_hot, excluded_cindex=[4,6,9])\n",
    "print(\"y_test_3 : \",check_cindex(y_test_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(learning_rate: float = 0.001):\n",
    "    # Define a simple CNN for CIFAR-10 and set Adam optimizer\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(32, 32, 3)),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        \"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.client import NumPyClient, ClientApp\n",
    "from flwr.common import ndarrays_to_parameters, Context\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server import ServerApp, ServerConfig\n",
    "from flwr.server import ServerAppComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(\n",
    "        self, model, data, epochs, batch_size, verbose\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test = data\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(\n",
    "            self.x_train,\n",
    "            self.y_train,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        return self.model.get_weights(), len(self.x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "        return loss, len(self.x_test), {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mdoel Evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,cur_x_test,cur_y_test):\n",
    "    \n",
    "    loss, accuracy = model.evaluate(cur_x_test,cur_y_test, verbose=0)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client function\n",
    "def client_fn1(context: Context) -> Client:\n",
    "    net = load_model()\n",
    "    client_data = (x_train_1,y_train_1,x_test_1,y_test_1)\n",
    "    epochs = 3,\n",
    "    batch_size = 32,\n",
    "    verbose =1\n",
    "    return FlowerClient(net, client_data, epochs,batch_size,verbose).to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ClientApp(client_fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_1 (7000, 32, 32, 3)\n",
      "y_test_1  (7000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_test_1\" ,x_test_1.shape)\n",
    "print(\"y_test_1 \" , y_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy on [1,3,7]:  0.08285713940858841\n"
     ]
    }
   ],
   "source": [
    "net = load_model()\n",
    "_, accuracy137 = evaluate_model(net, x_test_1,y_test_1)\n",
    "print(\"test accuracy on [1,3,7]: \", accuracy137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluate for model testing\n",
    "- The evaluate method evaluates the performance of the neural network model using the provided parameters and the test dataset (testset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(server_round, parameters, config):\n",
    "    net = load_model()\n",
    "    net.set_weights(parameters)\n",
    "\n",
    "    _, accuracy137 = evaluate_model(net, x_test_1,y_test_1)\n",
    "    _, accuracy258 = evaluate_model(net, x_test_2,y_test_2)\n",
    "    _, accuracy469 = evaluate_model(net, x_test_3,y_test_3)\n",
    "\n",
    "    print(\"test accuracy on [1,3,7]: \", accuracy137)\n",
    "    print(\"test accuracy on [2,5,8]: \", accuracy258)\n",
    "    print(\"test accuracy on [4,6,9]: \", accuracy469)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = load_model()\n",
    "params = ndarrays_to_parameters(net.get_weights())\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.0,\n",
    "        initial_parameters=params,\n",
    "        evaluate_fn=evaluate,\n",
    "    )\n",
    "    config=ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(\n",
    "        strategy=strategy,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=3,\n",
    "    #backend_config=backend_setup,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
